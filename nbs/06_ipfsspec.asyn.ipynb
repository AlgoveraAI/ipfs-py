{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e4fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp ipfsspec.asyn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2662e9e",
   "metadata": {},
   "source": [
    "# IPFSSpec \n",
    "> asyn implementation of ipfsspec for fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94df384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e0d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import weakref\n",
    "import copy\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import json\n",
    "from glob import has_magic\n",
    "from copy import deepcopy\n",
    "\n",
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "\n",
    "from fsspec.asyn import AsyncFileSystem, sync, sync_wrapper\n",
    "from fsspec.asyn import _run_coros_in_chunks\n",
    "from fsspec.utils import is_exception\n",
    "from fsspec.callbacks import _DEFAULT_CALLBACK\n",
    "from fsspec.exceptions import FSTimeoutError\n",
    "from fsspec.implementations.local import LocalFileSystem\n",
    "from fsspec.spec import AbstractBufferedFile\n",
    "from fsspec.utils import is_exception, other_paths\n",
    "\n",
    "from ipfshttpclient.multipart import stream_directory, stream_files #needed to prepare files/directory to be sent through http\n",
    "\n",
    "from ipfspy.utils import dict_get, dict_put, dict_hash, dict_equal\n",
    "from ipfspy.ipfsspec.gateway import MultiGateway, AsyncIPFSGateway\n",
    "from ipfspy.ipfsspec.bufferedfile import IPFSBufferedFile\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(\"ipfsspec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d7759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class RequestsTooQuick(OSError):\n",
    "    def __init__(self, retry_after=None):\n",
    "        self.retry_after = retry_after\n",
    "\n",
    "DEFAULT_GATEWAY = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class AsyncRequestSession: # this function is not used anywhere?\n",
    "    def __init__(self, loop=None, \n",
    "                adapter=dict(pool_connections=100, pool_maxsize=100), \n",
    "                **kwargs):\n",
    "                \n",
    "        self.session = requests.Session()\n",
    "        self.loop = loop\n",
    "        adapter = requests.adapters.HTTPAdapter(**adapter)\n",
    "        self.session.mount('http://', adapter)\n",
    "        self.session.mount('https://', adapter)\n",
    "\n",
    "    async def get(self, *args, **kwargs):\n",
    "        return await self.loop.run_in_executor(None, lambda x: self.session.get(*args,**kwargs), None)\n",
    "    \n",
    "    async def post(self, *args, **kwargs):\n",
    "        return await self.loop.run_in_executor(None, lambda x: self.session.post(*args, **kwargs), None)\n",
    "\n",
    "    async def close(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25815693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "IPFSHTTP_LOCAL_HOST = os.getenv('IPFSHTTP_LOCAL_HOST', '127.0.0.1')\n",
    "\n",
    "GATEWAY_MAP = {\n",
    "    'local': [f\"http://{IPFSHTTP_LOCAL_HOST}:8080\"],\n",
    "    # 'infura': ['https://ipfs.infura.io:5001'],\n",
    "    'public': [\"https://ipfs.io\",\n",
    "               \"https://gateway.pinata.cloud\",\n",
    "               \"https://cloudflare-ipfs.com\",\n",
    "               \"https://dweb.link\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc0ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class AsyncIPFSFileSystem(AsyncFileSystem):\n",
    "    sep = \"/\"\n",
    "    protocol = \"ipfs\"\n",
    "    root = '/tmp/fspec/ipfs'\n",
    "\n",
    "    def __init__(self, asynchronous=False,\n",
    "                 gateway_type='local',\n",
    "                loop=None, \n",
    "                root = None,\n",
    "                client_kwargs={},\n",
    "                 **storage_options):\n",
    "        super().__init__(self, asynchronous=asynchronous, loop=loop, **storage_options,)\n",
    "        self._session = None\n",
    "        self.client_kwargs=client_kwargs\n",
    "        self.gateway = None\n",
    "        self.change_gateway_type = gateway_type\n",
    "\n",
    "        self.local_fs = AsyncFileSystem(loop=loop)\n",
    "        if root:\n",
    "            self.root = root\n",
    "\n",
    "        if not asynchronous:\n",
    "            sync(self.loop, self.set_session)\n",
    "\n",
    "    @property\n",
    "    def change_gateway_type(self):\n",
    "        return self.gateway_type\n",
    "\n",
    "    @change_gateway_type.setter    \n",
    "    def change_gateway_type(self, value):\n",
    "        self.gateway_type = value\n",
    "        self.gateway = MultiGateway([AsyncIPFSGateway(url=url, gateway_type=self.gateway_type) for url in GATEWAY_MAP[self.gateway_type]])\n",
    "        print(f\"Changed to {self.gateway_type} node\")\n",
    "\n",
    "    # @property\n",
    "    # def gateway(self, gateway_type = None):\n",
    "    #     if gateway_type is None:\n",
    "    #         gateway_type = self.gateway_type\n",
    "    #     return MultiGateway.get_gateway(gateway_type=self.gateway_type)\n",
    "\n",
    "    @staticmethod\n",
    "    async def get_client(**kwargs):\n",
    "        timeout = aiohttp.ClientTimeout(sock_connect=1, sock_read=5)\n",
    "        kwargs = {\"timeout\": timeout, **kwargs}\n",
    "        return aiohttp.ClientSession(**kwargs)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def close_session(loop, session):\n",
    "        if loop is not None and loop.is_running():\n",
    "            try:\n",
    "                sync(loop, session.close, timeout=0.1)\n",
    "                return\n",
    "            except (TimeoutError, FSTimeoutError):\n",
    "                pass\n",
    "        if session._connector is not None:\n",
    "            # close after loop is dead\n",
    "            session._connector._close()\n",
    "\n",
    "    async def set_session(self, refresh=False):\n",
    "        if (not self._session) or (refresh==True):\n",
    "            self._session = await self.get_client(loop=self.loop, **self.client_kwargs)\n",
    "            if not self.asynchronous:\n",
    "                weakref.finalize(self, self.close_session, self.loop, self._session)\n",
    "        return self._session\n",
    "    \n",
    "    async def close(self):\n",
    "        \"\"\"Close file\n",
    "        Finalizes writes, discards cache\n",
    "        \"\"\"\n",
    "        if getattr(self, \"_unclosable\", False):\n",
    "            return\n",
    "        if self.closed:\n",
    "            return\n",
    "        if self.mode == \"rb\":\n",
    "            self.cache = None\n",
    "        else:\n",
    "            if not self.forced:\n",
    "                await self.flush(force=True)\n",
    "\n",
    "            if self.fs is not None:\n",
    "                self.fs.invalidate_cache(self.path)\n",
    "                self.fs.invalidate_cache(self.fs._parent(self.path))\n",
    "\n",
    "        self.closed = True\n",
    "\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.close_session(loop=self.loop, session=self._session)\n",
    "\n",
    "    async def _expand_path(self, path, recursive=False, maxdepth=None):\n",
    "        if isinstance(path, str):\n",
    "            out = await self._expand_path([path], recursive, maxdepth)\n",
    "        else:\n",
    "            # reduce depth on each recursion level unless None or 0\n",
    "            maxdepth = maxdepth if not maxdepth else maxdepth - 1\n",
    "            out = set()\n",
    "            path = [self._strip_protocol(p) for p in path]\n",
    "            for p in path:  # can gather here\n",
    "                if has_magic(p):\n",
    "                    bit = set(await self._glob(p))\n",
    "                    out |= bit\n",
    "                    if recursive:\n",
    "                        out |= set(\n",
    "                            await self._expand_path(\n",
    "                                list(bit), recursive=recursive, maxdepth=maxdepth\n",
    "                            )\n",
    "                        )\n",
    "                    continue\n",
    "                elif recursive:\n",
    "                    \n",
    "                    rec = set(await self._find(p, maxdepth=maxdepth, withdirs=True))\n",
    "                    out |= rec\n",
    "\n",
    "                if p not in out and (recursive is False or (await self._exists(p))):\n",
    "                    # should only check once, for the root\n",
    "                    out.add(p)\n",
    "        if not out:\n",
    "            raise FileNotFoundError(path)\n",
    "        return list(sorted(out))\n",
    "\n",
    "    async def _rm_file(self ,path, gc=True, **kwargs):\n",
    "        session = await self.set_session()\n",
    "        response = await self.gateway.api_post(session=session, endpoint='files/rm', recursive='true', arg=path)\n",
    "        if gc:\n",
    "            await self.gateway.api_post(session=session, endpoint='repo/gc')\n",
    "        return path\n",
    "\n",
    "    # async def _rm(self, path, recursion=True , gc=True,**kwargs):\n",
    "    #     recursion='true' if recursion else 'false'\n",
    "    #     session = await self.set_session()\n",
    "    #     await self.gateway.api_post(session=session, endpoint='files/rm', recursion=recursion, arg=path)\n",
    "    #     if gc:\n",
    "    #         await self.gateway.api_post(session=session, endpoint='repo/gc')\n",
    "\n",
    "    @staticmethod\n",
    "    def ensure_path(path):\n",
    "        assert isinstance(path, str), f'path must be string, but got {path}'\n",
    "        if len(path) == 0:\n",
    "            path = '/'\n",
    "        elif len(path) > 0:\n",
    "            if path[0] != '/':\n",
    "                path = '/' + path\n",
    "        \n",
    "        return path\n",
    "\n",
    "\n",
    "    async def  _stat(self, path):\n",
    "        session = await self.set_session()\n",
    "\n",
    "        res = await self.gateway.api_get(endpoint='files/stat', session=session, path=path)\n",
    "        return res\n",
    "    stat = sync_wrapper(_stat)\n",
    "\n",
    "    async def _ls(self, path='/', detail=True, recursive=False, **kwargs):\n",
    "        # path = self._strip_protocol(path)\n",
    "\n",
    "        session = await self.set_session()\n",
    "        res = await self.gateway.ls(session=session, path=path)\n",
    "\n",
    "        if recursive:\n",
    "            # this is prob not needed with self.find\n",
    "            res_list = []\n",
    "            cor_list = []\n",
    "            for r in res:\n",
    "                if r['type'] == 'directory':\n",
    "                    cor_list.append(self._ls(path=r['name'], detail=True, recursive=recursive, **kwargs))\n",
    "                elif r['type'] == 'file':\n",
    "                    res_list += [r]\n",
    "                    \n",
    "            if len(cor_list) > 0:\n",
    "                for r in (await asyncio.gather(*cor_list)):\n",
    "                    res_list += r\n",
    "            res = res_list\n",
    "\n",
    "\n",
    "        if detail:\n",
    "            return res\n",
    "        else:\n",
    "            return [r[\"name\"] for r in res]\n",
    "\n",
    "    ls = sync_wrapper(_ls)\n",
    "\n",
    "    # def _store_path(self, path, hash):\n",
    "\n",
    "\n",
    "\n",
    "    async def _is_pinned(self, cid):\n",
    "        session = await self.set_session()\n",
    "        res = await self.gateway.api_post(endpoint='pin/ls', session=session, params={'arg':cid})\n",
    "        pinned_cid_list = list(json.loads(res.decode()).get('Keys').keys())\n",
    "        return bool(cid in pinned_cid_list)\n",
    "\n",
    "    is_pinned = sync_wrapper(_is_pinned)\n",
    "\n",
    "\n",
    "    async def _pin(self, cid, recursive=False, progress=False):\n",
    "        session = await self.set_session()\n",
    "        res = await self.gateway.api_post(endpoint='pin/add', session=session, params={'arg':cid, \n",
    "                                                                     'recursive': recursive,\n",
    "                                                                      'progress': progress})\n",
    "        return bool(cid in pinned_cid_list)\n",
    "\n",
    "    pin = sync_wrapper(_pin)\n",
    "\n",
    "\n",
    "    async def _api_post(self, endpoint, **kwargs):\n",
    "        session = await self.set_session()\n",
    "        return await self.gateway.api_post(endpoint=endpoint, session=session, **kwargs)\n",
    "    api_post = sync_wrapper(_api_post)\n",
    "\n",
    "    async def _api_get(self, endpoint, **kwargs):\n",
    "        session = await self.set_session()\n",
    "        res =  await self.gateway.api_get(endpoint=endpoint, session=session, **kwargs)\n",
    "        if res.headers['Content-Type'] == 'application/json':\n",
    "            res = await res.json()\n",
    "        elif res.headers['Content-Type'] == 'text/plain':\n",
    "            res = json.loads((await res.content.read()).decode())\n",
    "        return res\n",
    "    api_get = sync_wrapper(_api_get)\n",
    "\n",
    "    async def _cp(self,path1, path2):\n",
    "        session = await self.set_session()\n",
    "        res = await self.gateway.cp(session=session, arg=[path1, path2])\n",
    "        return res\n",
    "    cp = sync_wrapper(_cp)\n",
    "\n",
    "    async def _put_file(self,\n",
    "        lpath=None,\n",
    "        rpath=None,\n",
    "        pin=True,\n",
    "        chunker=262144, \n",
    "        wrap_with_directory=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        if 'path' in kwargs:\n",
    "            lpath = kwargs.pop('path')\n",
    "\n",
    "        session = await self.set_session()\n",
    "        if not os.path.isfile(lpath): raise TypeError ('Use `put` to upload a directory')        \n",
    "        if self.gateway_type == 'public': raise TypeError ('`put_file` and `put` functions require local/infura `gateway_type`')\n",
    "        \n",
    "        params = {}\n",
    "        params['wrap-with-directory'] = 'true' if wrap_with_directory else 'false'\n",
    "        params['chunker'] = f'size-{chunker}'\n",
    "        params['pin'] = 'true' if pin else 'false'\n",
    "        \n",
    "        data, headers = stream_files(lpath, chunk_size=chunker)\n",
    "        data = self.data_gen_wrapper(data=data)                                        \n",
    "        res = await self.gateway.api_post(endpoint='add', session=session,  params=params, data=data, headers=headers)\n",
    "\n",
    "        res =  await res.json()\n",
    "\n",
    "        return res\n",
    "        # return res\n",
    "    \n",
    "    @staticmethod\n",
    "    async def data_gen_wrapper(data):\n",
    "        for d in data:\n",
    "            yield d\n",
    "\n",
    "\n",
    "    async def _put(self,\n",
    "        lpath=None, \n",
    "        rpath=None,\n",
    "        recursive=True,\n",
    "        pin=True,\n",
    "        chunker=262144, \n",
    "        return_json=True,\n",
    "        return_cid = True,\n",
    "        wrap_with_directory=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \n",
    "        # if self.gateway_type == 'public': raise TypeError ('`put_file` and `put` functions require local/infura `gateway_type`')\n",
    "        \n",
    "        session = await self.set_session()\n",
    "\n",
    "        if 'path' in kwargs:\n",
    "            lpath = kwargs.pop('path')\n",
    "\n",
    "        if rpath[0] != '/' and len(rpath) > 1:\n",
    "            rpath = '/' + rpath \n",
    "\n",
    "        params = {}\n",
    "        params['chunker'] = f'size-{chunker}'\n",
    "        params['pin'] = 'true' if pin else 'false'\n",
    "        params.update(kwargs)\n",
    "        params['wrap-with-directory'] = 'true' if wrap_with_directory else 'false'\n",
    "\n",
    "\n",
    "        assert os.path.exists(lpath), f'{lpath} does not exists'\n",
    "        local_isdir = os.path.isdir(lpath)\n",
    "        local_isfile = os.path.isfile(lpath)\n",
    "\n",
    "        assert bool(local_isfile) != bool(local_isdir), \\\n",
    "                f'WTF, local_isfile: {local_isfile} && local_isdir: {local_isdir}'\n",
    "        \n",
    "        if local_isdir:\n",
    "            assert bool(local_isfile) == False\n",
    "            data, headers = stream_directory(lpath, chunk_size=chunker, recursive=recursive)\n",
    "        else:\n",
    "            assert bool(local_isfile) == True\n",
    "            data, headers = stream_files(lpath, chunk_size=chunker)\n",
    "        \n",
    "        \n",
    "        data = self.data_gen_wrapper(data=data)                             \n",
    "        res = await self.gateway.api_post(endpoint='add', session=session, params=params, data=data, headers=headers)\n",
    "        \n",
    "        res =  await res.content.read()\n",
    "        res = list(map(lambda x: json.loads(x), filter(lambda x: bool(x),  res.decode().split('\\n'))))\n",
    "        res = list(filter(lambda x: isinstance(x, dict) and x.get('Name'), res))\n",
    "        res_hash = res[-1][\"Hash\"]\n",
    "        \n",
    "        if pin and not rpath:\n",
    "            rpath='/'\n",
    "        if rpath:\n",
    "            \n",
    "            if  local_isdir:\n",
    "                await self._cp(path1=f'/ipfs/{res[-1][\"Hash\"]}', path2=rpath )\n",
    "            else:\n",
    "\n",
    "                cid_hash = res[-1][\"Hash\"]\n",
    "                ipfs_path = f'/ipfs/{cid_hash}'\n",
    "                tmp_path = f'{rpath}/{cid_hash}'\n",
    "                rdir = os.path.dirname(tmp_path)\n",
    "                final_path = f'{rpath}/{os.path.basename(lpath)}'\n",
    "                if not (await self._isdir(rdir)):\n",
    "                    await self._mkdir(path=rdir)\n",
    "\n",
    "\n",
    "                if rdir[-1] != '/' and len(rdir) > 1:\n",
    "                    rdir = rdir + '/'\n",
    "                await self._cp(path1=ipfs_path, path2=rdir  )\n",
    "                ipfs_path = f'/{rpath}/{cid_hash}'\n",
    "                await self._cp(path1=tmp_path, path2=final_path )\n",
    "                await self._rm_file(ipfs_path)\n",
    "        \n",
    "        \n",
    "        if return_cid:\n",
    "            return res_hash\n",
    "        return res\n",
    "\n",
    "    put = sync_wrapper(_put)\n",
    "\n",
    "\n",
    "    async def _mkdir(self, path):\n",
    "        session = await self.set_session()\n",
    "        return await self.gateway.api_post(session=session, endpoint='files/mkdir', arg=path)\n",
    "    async def _rm(self, path, recursive=False, batch_size=None, **kwargs):\n",
    "        # TODO: implement on_error\n",
    "        batch_size = batch_size or self.batch_size\n",
    "\n",
    "        try:\n",
    "            paths = await self._expand_path([path], recursive=recursive)\n",
    "        except Exception:\n",
    "            return []\n",
    "        # paths = await self.filter_files(paths)\n",
    "        return await _run_coros_in_chunks(\n",
    "            [self._rm_file(p, **kwargs) for p in paths],\n",
    "            batch_size=batch_size,\n",
    "            nofiles=True,\n",
    "        )\n",
    "\n",
    "    async def _cat_file(self, path, start=None, end=None, **kwargs):\n",
    "        path = self._strip_protocol(path)\n",
    "        \n",
    "        \n",
    "        session = await self.set_session()\n",
    "        return (await self.gateway.cat(session=session, path=path))[start:end]\n",
    "    \n",
    "    async def filter_files(self, paths):\n",
    "        async def _file_filter(p):\n",
    "            # FIX: returns path if file, else returns False\n",
    "            if await self._isfile(p):\n",
    "                return p\n",
    "            else:\n",
    "                return False\n",
    "        paths = [_ for _ in await asyncio.gather(*[ _file_filter(p) for p in paths]) if bool(_) ]\n",
    "        return paths\n",
    "\n",
    "    async def _cat(\n",
    "            self, path, recursive=False, on_error=\"raise\", batch_size=None, **kwargs\n",
    "        ):\n",
    "\n",
    "\n",
    "            if await self._isdir(path=path):\n",
    "                recursive = True\n",
    "            \n",
    "            paths = await self._expand_path(path, recursive=recursive)\n",
    "            paths = await self.filter_files(paths)\n",
    "            # print(paths, 'PATHS', path)\n",
    "            coros = [self._cat_file(path, **kwargs) for path in paths]\n",
    "            batch_size = batch_size or self.batch_size\n",
    "            out = await _run_coros_in_chunks(\n",
    "                coros, batch_size=batch_size, nofiles=True, return_exceptions=True\n",
    "            )\n",
    "            if on_error == \"raise\":\n",
    "                ex = next(filter(is_exception, out), False)\n",
    "                if ex:\n",
    "                    raise ex\n",
    "            \n",
    "            assert len(paths) == len(out)\n",
    "            if (\n",
    "                len(out) >= 1\n",
    "            ):\n",
    "                if await self._isdir(path):\n",
    "                    return {\n",
    "                        k: v\n",
    "                        for k, v in zip(paths, out)\n",
    "                        if on_error != \"omit\" or not is_exception(v)\n",
    "                    }\n",
    "                else:\n",
    "                    return out[0]\n",
    "\n",
    "            else:\n",
    "                raise Exception(f'WTF, out is not suppose to be <1 , len: {len(out)}')\n",
    "    async def _info(self, path, **kwargs):\n",
    "        path = self._strip_protocol(path)\n",
    "        session = await self.set_session()\n",
    "        info = await self.gateway.file_info(session=session, path=path)\n",
    "        return info\n",
    "\n",
    "    def open(self, path, mode=\"rb\",  block_size=\"default\",autocommit=True,\n",
    "                cache_type=\"readahead\", cache_options=None, size=None, **kwargs):\n",
    "        \n",
    "        return IPFSBufferedFile(\n",
    "                            fs=self,\n",
    "                            path=path,\n",
    "                            mode=mode,\n",
    "                            block_size=block_size,\n",
    "                            autocommit=autocommit,\n",
    "                            cache_type=cache_type,\n",
    "                            cache_options=cache_options,\n",
    "                            size=size\n",
    "                        )\n",
    "\n",
    "        # if mode == 'rb':\n",
    "        #     data = self.cat_file(path)  # load whole chunk into memory\n",
    "        #     return io.BytesIO(data)\n",
    "        # elif mode == 'wb':\n",
    "        #     self.put_file(path)\n",
    "        # else:\n",
    "        #     raise NotImplementedError\n",
    "\n",
    "    def ukey(self, path):\n",
    "        \"\"\"returns the CID, which is by definition an unchanging identitifer\"\"\"\n",
    "        return self.info(path)[\"CID\"]\n",
    "\n",
    "    # async def _get(self,\n",
    "    #     rpath,\n",
    "    #     lpath=None,\n",
    "    #     **kwargs\n",
    "    # ):\n",
    "    #     if 'path' in kwargs:\n",
    "    #         lpath = kwargs.pop('path')\n",
    "        \n",
    "    #     session = await self.set_session()\n",
    "    #     if lpath is None: lpath = os.getcwd()\n",
    "    #     self.full_structure = await self.gateway.get_links(session=session, rpath=rpath, lpath=lpath)\n",
    "    #     await self.gateway.save_links(session=session, links=self.full_structure)\n",
    "    # get=sync_wrapper(_get)\n",
    "\n",
    "    async def _get_file(self, rpath, lpath, **kwargs):\n",
    "        import shutil\n",
    "        session = self._session\n",
    "        # shutil.rmtree(lpath)\n",
    "        data = await self._cat(path=rpath)\n",
    "        f = open(lpath, mode='wb')\n",
    "        f.write(data)\n",
    "        f.close()\n",
    "\n",
    "    async def _get(\n",
    "        self, rpath, lpath, recursive=True, callback=_DEFAULT_CALLBACK, **kwargs\n",
    "    ):\n",
    "        \"\"\"Copy file(s) to local.\n",
    "        Copies a specific file or tree of files (if recursive=True). If lpath\n",
    "        ends with a \"/\", it will be assumed to be a directory, and target files\n",
    "        will go within. Can submit a list of paths, which may be glob-patterns\n",
    "        and will be expanded.\n",
    "        The get_file method will be called concurrently on a batch of files. The\n",
    "        batch_size option can configure the amount of futures that can be executed\n",
    "        at the same time. If it is -1, then all the files will be uploaded concurrently.\n",
    "        The default can be set for this instance by passing \"batch_size\" in the\n",
    "        constructor, or for all instances by setting the \"gather_batch_size\" key\n",
    "        in ``fsspec.config.conf``, falling back to 1/8th of the system limit .\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        if len(lpath.split('.')) == 1 and len(lpath) > 1 and lpath[-1] != '/' :\n",
    "            lpath += '/'\n",
    "        from fsspec.implementations.local import make_path_posix\n",
    "\n",
    "        rpath = self._strip_protocol(rpath)\n",
    "        lpath = make_path_posix(lpath)\n",
    "\n",
    "        root_dir_lpath = lpath if os.path.isdir(lpath) else os.path.dirname(lpath)\n",
    "\n",
    "        rpaths = await self._expand_path(rpath, recursive=recursive)\n",
    "        \n",
    "        if len(lpath.split('.')) == 1:\n",
    "            lpaths = other_paths(rpaths, lpath)\n",
    "            [os.makedirs(os.path.dirname(lp), exist_ok=True) for lp in lpaths]\n",
    "        else:\n",
    "            lpaths = [lpath]\n",
    "\n",
    "        batch_size = kwargs.pop(\"batch_size\", self.batch_size)\n",
    "        temp_rpaths, temp_lpaths = [], []\n",
    "\n",
    "        for i,lp in enumerate(lpaths):\n",
    "            if len(lp.split('.')) == 2:\n",
    "                temp_rpaths.append(rpaths[i])\n",
    "                temp_lpaths.append(lpaths[i])\n",
    "            \n",
    "            else:\n",
    "                if await self._isfile(rpaths[i]):\n",
    "                    temp_lpaths.append(os.path.join(lpaths[i]+''))\n",
    "                    temp_rpaths.append(rpaths[i])\n",
    "\n",
    "        rpaths = temp_rpaths\n",
    "        lpaths = temp_lpaths\n",
    "        # #TODO: not good for hidden files\n",
    "        # lpaths = list(filter(lambda f: self.local_fs.isfile(f),lpaths))\n",
    "        \n",
    "        coros = []\n",
    "        callback.set_size(len(lpaths))\n",
    "        for lpath, rpath in zip(lpaths, rpaths):\n",
    "            callback.branch(rpath, lpath, kwargs)\n",
    "            coros.append(self._get_file(rpath, lpath, **kwargs))\n",
    "        return await _run_coros_in_chunks(\n",
    "            coros, batch_size=batch_size, callback=callback\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede63347",
   "metadata": {},
   "source": [
    "## Changing Gateways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f6325-2ddb-4b6d-9a5c-b522967d6a8e",
   "metadata": {},
   "source": [
    "To learn more about the fsspec api, please see the dock [here](https://filesystem-spec.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c37d4a-1ac3-4bdd-b4ff-56b5ad1bd690",
   "metadata": {},
   "source": [
    "Register ipfsspec to fsspec,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8336f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|ignoretest\n",
    "import fsspec, os, io, glob, asyncio\n",
    "from ipfspy.ipfsspec.asyn import AsyncIPFSFileSystem\n",
    "from fsspec import register_implementation\n",
    "\n",
    "# register_implementation(IPFSFileSystem.protocol, IPFSFileSystem)\n",
    "register_implementation(AsyncIPFSFileSystem.protocol, AsyncIPFSFileSystem)\n",
    "\n",
    "# with fsspec.open(\"ipfs://QmZ4tDuvesekSs4qM5ZBKpXiZGun7S2CYtEZRB3DYXkjGx\", \"r\") as f:\n",
    "#     print(f.read())\n",
    "class fs:\n",
    "    ipfs = fsspec.filesystem(\"ipfs\")\n",
    "    file = fsspec.filesystem(\"file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7339d3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed to public node\n"
     ]
    }
   ],
   "source": [
    "#|ignoretest\n",
    "fs.ipfs.change_gateway_type = 'public'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24281721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed to local node\n"
     ]
    }
   ],
   "source": [
    "#|ignoretest\n",
    "fs.ipfs.change_gateway_type = 'local'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f30fe4-cedf-481d-8ee1-884b84b0a38b",
   "metadata": {},
   "source": [
    "## Using `Local` node "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cd3eca-ed4d-407b-bf1d-dad65ec9dad6",
   "metadata": {},
   "source": [
    "Put File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755bd9f2-f7a9-4e86-98f1-47334c0cc029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QmbwFKzLj9m2qwBFYTVrBotf4QujvzTb1GBV9wFcNPMctm'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|ignoretest\n",
    "fs.ipfs.put(path='output/test.txt', rpath='/test_put_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b7092-40ea-49aa-ae3a-1c7c2a157762",
   "metadata": {},
   "source": [
    "Put Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a4792b-3a3b-4990-8ebb-d1ddb9a5ebbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Name': 'fol2/test2.txt',\n",
       "  'Hash': 'QmZCFrtagSLhiHKAywF8oWxapXtR6JiJ8GeENASyhLvvyu',\n",
       "  'Size': '28'},\n",
       " {'Name': 'fol2/test.txt',\n",
       "  'Hash': 'QmbwFKzLj9m2qwBFYTVrBotf4QujvzTb1GBV9wFcNPMctm',\n",
       "  'Size': '28'},\n",
       " {'Name': 'fol2/test3.txt',\n",
       "  'Hash': 'QmWT5UmZ4zoXX9GsXpPtEMVP5m1VZ7N6rdxnXHGNkFKqFJ',\n",
       "  'Size': '36'},\n",
       " {'Name': 'fol2/.ipynb_checkpoints',\n",
       "  'Hash': 'QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn',\n",
       "  'Size': '4'},\n",
       " {'Name': 'fol2',\n",
       "  'Hash': 'QmWHpqeDLAMMuLSKDqcMNZRaZGwEKbY5FoU7DMA3pftj54',\n",
       "  'Size': '312'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|ignoretest\n",
    "fs.ipfs.put(path='output/fol1/fol2', rpath='/test_put_folder', recursive=True, return_cid=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1935aaf5-823a-4a2a-b6f6-cf597fe0d1d6",
   "metadata": {},
   "source": [
    "Cat File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d4902-8e5e-428c-87e9-5de8c7e63831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"\\n'''\\nFirst file\\n'''\\n\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|ignoretest\n",
    "fs.ipfs.cat('QmbwFKzLj9m2qwBFYTVrBotf4QujvzTb1GBV9wFcNPMctm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a12400-0e77-478c-847d-0a4ddffa18ce",
   "metadata": {},
   "source": [
    "Cat Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1440a039-765a-4681-9a74-a5c682831d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QmWHpqeDLAMMuLSKDqcMNZRaZGwEKbY5FoU7DMA3pftj54/test.txt': b\"\\n'''\\nFirst file\\n'''\\n\",\n",
       " 'QmWHpqeDLAMMuLSKDqcMNZRaZGwEKbY5FoU7DMA3pftj54/test2.txt': b'```\\nsecond file\\n```\\n',\n",
       " 'QmWHpqeDLAMMuLSKDqcMNZRaZGwEKbY5FoU7DMA3pftj54/test3.txt': b\"\\n'''\\nthis is third file\\n'''\\n\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|ignoretest\n",
    "fs.ipfs.cat('QmWHpqeDLAMMuLSKDqcMNZRaZGwEKbY5FoU7DMA3pftj54')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482d3e90-36f4-48e7-b7dd-749b34a264d9",
   "metadata": {},
   "source": [
    "List a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd4f1a5-30bb-4ee9-87d1-ffbd7ce7b544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'QmWHpqeDLAMMuLSKDqcMNZRaZGwEKbY5FoU7DMA3pftj54/.ipynb_checkpoints',\n",
       "  'CID': 'QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn',\n",
       "  'type': 'directory',\n",
       "  'size': 0},\n",
       " {'name': 'QmWHpqeDLAMMuLSKDqcMNZRaZGwEKbY5FoU7DMA3pftj54/test.txt',\n",
       "  'CID': 'QmbwFKzLj9m2qwBFYTVrBotf4QujvzTb1GBV9wFcNPMctm',\n",
       "  'type': 'file',\n",
       "  'size': 20},\n",
       " {'name': 'QmWHpqeDLAMMuLSKDqcMNZRaZGwEKbY5FoU7DMA3pftj54/test2.txt',\n",
       "  'CID': 'QmZCFrtagSLhiHKAywF8oWxapXtR6JiJ8GeENASyhLvvyu',\n",
       "  'type': 'file',\n",
       "  'size': 20},\n",
       " {'name': 'QmWHpqeDLAMMuLSKDqcMNZRaZGwEKbY5FoU7DMA3pftj54/test3.txt',\n",
       "  'CID': 'QmWT5UmZ4zoXX9GsXpPtEMVP5m1VZ7N6rdxnXHGNkFKqFJ',\n",
       "  'type': 'file',\n",
       "  'size': 28}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|ignoretest\n",
    "fs.ipfs.ls('QmWHpqeDLAMMuLSKDqcMNZRaZGwEKbY5FoU7DMA3pftj54')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58cf4cb-2a59-4668-815f-886487f8a4c3",
   "metadata": {},
   "source": [
    "Get a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423095fc-f21d-41e6-a07d-0fccc57fd3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  []\n",
      "After:  ['output/get_file/QmWT5UmZ4zoXX9GsXpPtEMVP5m1VZ7N6rdxnXHGNkFKqFJ']\n"
     ]
    }
   ],
   "source": [
    "#|ignoretest\n",
    "def test_get_public_cid(cid='QmWT5UmZ4zoXX9GsXpPtEMVP5m1VZ7N6rdxnXHGNkFKqFJ', \n",
    "                        rpath='/test_get_file',\n",
    "                        out_lpath = 'output/get_file/', \n",
    "                        gateway_type=None):\n",
    "    if gateway_type:\n",
    "        fs.ipfs.change_gateway_type = 'local'\n",
    "    if fs.file.exists(out_lpath):\n",
    "        fs.file.rm(out_lpath, recursive=True)\n",
    "        \n",
    "    fs.ipfs.rm(rpath, recursive=True)\n",
    "    print('Before: ', [p.lstrip(os.getcwd()) for p in fs.file.glob(f'{out_lpath}/*')])\n",
    "    \n",
    "    fs.ipfs.get(rpath=cid, lpath=out_lpath, recursive=True, return_cid=False)\n",
    "    print('After: ', [p.lstrip(os.getcwd()) for p in fs.file.glob(f'{out_lpath}/*')])\n",
    "    \n",
    "    fs.ipfs.rm(rpath, recursive=True)\n",
    "\n",
    "test_get_public_cid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e40cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.doclinks import *\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5487e277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
