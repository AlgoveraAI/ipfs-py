{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp ipfsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "905db426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e4d9a",
   "metadata": {},
   "source": [
    "# IPFSSpec\n",
    "\n",
    "> Read and Write implementation FSSpec for IPFS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "73d3abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0e8cd30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from os.path import isdir\n",
    "from typing import Union, List\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from requests.exceptions import HTTPError\n",
    "from fsspec.spec import AbstractFileSystem\n",
    "from ipfsspec.core import IPFSBufferedFile\n",
    "from ipfshttpclient.multipart import stream_files, stream_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b8e17c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from ipfspy.utils import GATEWAYS_API_READ, GATEWAYS_API_WRITE, parse_error_message, parse_response, get_coreurl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c8bf67",
   "metadata": {},
   "source": [
    "## IPFSGateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "523ef25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IPFSGateway:\n",
    "    def __init__(self, \n",
    "        local:bool=True, # Use local IPFS deamon or not\n",
    "        coreurl:str=None, # Core URL of an alterative gateways to use \n",
    "    ):\n",
    "        'Starts a IPFS Gateway either using local node or infura. If given `coreurl`, will use that for the gateway'\n",
    "        self.coreurl = coreurl\n",
    "        if self.coreurl is None:\n",
    "            self.url = self.get_gateway(local=local)\n",
    "            \n",
    "        else:\n",
    "            self.url = self.get_gateway(coreurl=coreurl)\n",
    "            \n",
    "        self.session = requests.Session()\n",
    "        adapter = requests.adapters.HTTPAdapter(pool_connections=100, pool_maxsize=100)\n",
    "        self.session.mount('http://', adapter)\n",
    "        self.session.mount('https://', adapter)\n",
    "    \n",
    "    def get_gateway(self,\n",
    "        local:bool=True, # If local uses local node, else uses Infura.io gateway\n",
    "        coreurl:str=None, # URL of other gateways\n",
    "    ):\n",
    "        'Set the core url for convenience'\n",
    "        \n",
    "        return get_coreurl(local=local, coreurl=coreurl)\n",
    "\n",
    "        \n",
    "    def get(self, \n",
    "        cid:str, # Path to the IPFS object\n",
    "        **kwargs\n",
    "    ):\n",
    "        'Get a file/directory from IPFS'\n",
    "        \n",
    "        params = {}\n",
    "        params['arg'] = cid\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        res = self.session.post(f'{self.url}/get', params=params)\n",
    "            \n",
    "        if res.status_code == 200:\n",
    "            return res, parse_response(res)\n",
    "        \n",
    "        else:\n",
    "            raise HTTPError (parse_error_message(res))\n",
    "            \n",
    "    def cat(self, \n",
    "        cid:str, # Path to the IPFS object\n",
    "        **kwargs\n",
    "    ):\n",
    "        'Read a file from IPFS'\n",
    "        \n",
    "        params = {}\n",
    "        params['arg'] = cid\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        res = self.session.post(f'{self.url}/cat', params=params)\n",
    "        \n",
    "        if res.status_code == 200:\n",
    "            return res, res.text\n",
    "        \n",
    "        else:\n",
    "            if res.status_code == 500:\n",
    "                raise TypeError (f\"dag node {path} is a directory; Provide a file CID\")\n",
    "            else:\n",
    "                raise HTTPError (parse_error_message(res))\n",
    "\n",
    "    def apipost(self, \n",
    "        call:str, # The call type to post e.g. 'add', 'ls', 'pin/add', 'pin/ls'\n",
    "        filepath:Union[str, List[str]]=None, # Path to files or directory or IPFS Path\n",
    "        directory:bool=False, # Is filepath a directory \n",
    "        chunk_size=200000, # Chunk size to use\n",
    "        **kwargs): \n",
    "        'Makes `post` call to the HTTP APPI'\n",
    "    \n",
    "        \n",
    "        if call == 'add':\n",
    "            if isdir(filepath):\n",
    "                if directory == False:\n",
    "                    raise TypeError (f\"{filepath} is a directory. Set arg directory as True\")\n",
    "            \n",
    "            params = {}\n",
    "            params.update(kwargs)\n",
    "            \n",
    "            if not directory:\n",
    "                data, headers = stream_files(filepath, chunk_size=chunk_size)\n",
    "\n",
    "            else:\n",
    "                data, headers = stream_directory(filepath, chunk_size=chunk_size)\n",
    "            \n",
    "            res = self.session.post(f'{self.url}/add',\n",
    "                                     params=params,\n",
    "                                     data=data,\n",
    "                                     headers=headers)\n",
    "            \n",
    "            if res.status_code == 200:\n",
    "                return res, parse_response(res)\n",
    "            \n",
    "            else:\n",
    "                raise HTTPError (parse_error_message(res))\n",
    "                \n",
    "        else:\n",
    "            params = {}\n",
    "            params['arg'] = filepath\n",
    "            params.update(kwargs)\n",
    "            \n",
    "            res = self.session.post(f'{self.url}/{call}', params=params)\n",
    "                \n",
    "            if res.status_code == 200:\n",
    "                return res, parse_response(res)\n",
    "            \n",
    "            else:\n",
    "                raise HTTPError (parse_error_message(res))\n",
    "\n",
    "    def head(self, \n",
    "        cid:str, # Path to the IPFS object\n",
    "        headers=None, \n",
    "        **kwargs\n",
    "    ):     \n",
    "        \n",
    "        res,_ = self.get(cid)\n",
    "        \n",
    "        return res.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d722e0",
   "metadata": {},
   "source": [
    "### Using IPFSGateway\n",
    "\n",
    "Using local-node supports all function. Infura gateway supports both read and write but not the complete set as offered by the local-node. We have a list of read and read/write gateways. You can access them as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "095253e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://ipfs.io/api/v0',\n",
       " 'https://gateway.pinata.cloud/api/v0',\n",
       " 'https://cloudflare-ipfs.com/api/v0',\n",
       " 'https://dweb.link/api/v0',\n",
       " 'https://ipfs.eth.aragon.network/api/v0',\n",
       " 'https://permaweb.eu.org/api/v0',\n",
       " 'https://nftstorage.link/api/v0',\n",
       " 'https://ipfs.lain.la/api/v0',\n",
       " 'https://ipfs.mihir.ch/api/v0',\n",
       " 'https://ipfs.telos.miami/api/v0',\n",
       " 'https://jorropo.net/api/v0',\n",
       " 'https://cf-ipfs.com/api/v0',\n",
       " 'https://cloudflare-ipfs.com/api/v0',\n",
       " 'https://gateway.ipfs.io/api/v0',\n",
       " 'https://infura-ipfs.io/api/v0',\n",
       " 'https://via0.com/api/v0',\n",
       " 'https://ipfs.azurewebsites.net/api/v0']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignoretest\n",
    "GATEWAYS_API_READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1db812fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://ipfs.io/api/v0',\n",
       " 'https://gateway.pinata.cloud/api/v0',\n",
       " 'https://cloudflare-ipfs.com/api/v0',\n",
       " 'https://dweb.link/api/v0']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignoretest\n",
    "GATEWAYS_API_WRITE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a028cac2",
   "metadata": {},
   "source": [
    "In this doc, we will be using the local-node unless specified. \n",
    "\n",
    "Extending a client session using the local node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89c518cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.1:5001/api/v0'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignoretest\n",
    "gw = IPFSGateway(local=True); gw.url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6665fa3",
   "metadata": {},
   "source": [
    "Extending a client session using infura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3a6e8fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ipfs.infura.io:5001/api/v0'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignoretest\n",
    "gw = IPFSGateway(local=False); gw.url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51aa8e2",
   "metadata": {},
   "source": [
    "Extending a client session using a public gateway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7af3ef9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://jorropo.net/api/v0'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignoretest\n",
    "gw = IPFSGateway(coreurl=random.choice(GATEWAYS_API_READ)); gw.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "64dab587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"IPFSGateway.get\" class=\"doc_header\"><code>IPFSGateway.get</code><a href=\"__main__.py#L29\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>IPFSGateway.get</code>(**`cid`**:`str`, **\\*\\*`kwargs`**)\n",
       "\n",
       "Get a file/directory from IPFS\n",
       "\n",
       "||Type|Default|Details|\n",
       "|---|---|---|---|\n",
       "|**`cid`**|`str`||Path to the IPFS object|\n",
       "|**`kwargs`**|||*No Content*|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ignoretest\n",
    "show_doc(IPFSGateway.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a401dacc",
   "metadata": {},
   "source": [
    "Let's use a local-node to get a IPFS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "41d4cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignoretest\n",
    "gw = IPFSGateway(local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "48eeb367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00# Welcome to Immerse by Algovera\\r\\n> A python library by Algovera to interact with IPFS and IPFS ecosystem such as the common pinning services\\r\\n\\r\\n\\r\\n## What is Immerse?\\r\\n\\r\\nImmerse is a pytho'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignoretest\n",
    "res, cont = gw.get('QmUfwG4P6EA5xbD3De5bS7XKcBion8ReQj7m9ZjxaPvq3B'); cont[500:700]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed57e46",
   "metadata": {},
   "source": [
    "Use the `cat` function which return the file without the headers and other stuffs that the `get` method returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eeed5cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"IPFSGateway.cat\" class=\"doc_header\"><code>IPFSGateway.cat</code><a href=\"__main__.py#L47\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>IPFSGateway.cat</code>(**`cid`**:`str`, **\\*\\*`kwargs`**)\n",
       "\n",
       "Read a file from IPFS\n",
       "\n",
       "||Type|Default|Details|\n",
       "|---|---|---|---|\n",
       "|**`cid`**|`str`||Path to the IPFS object|\n",
       "|**`kwargs`**|||*No Content*|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ignoretest\n",
    "show_doc(IPFSGateway.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bd5fe903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Welcome to Immerse by Algovera\\r\\n> A python library by Algovera to interact with IPFS and IPFS ecosystem such as the common pinning services\\r\\n\\r\\n\\r\\n## What is Immerse?\\r\\n\\r\\nImmerse is a python library by Algovera to interact with IPFS and IPFS ecosystem such as the common pinning services. It is designed by data scientists for data scientists to interact with the IPFS ecosystem without leaving the comfort of python and jupyter notebook.\\r\\n\\r\\nYou can learn more about IPFS [here](https://ipfs.io/#why)\\r\\n\\r\\nIPFS is built using the go-lang and javascript. With Immerse, you can interact with IPFS using the exposed [HTTP RPC API](https://docs.ipfs.io/reference/http/api/#getting-started). \\r\\n\\r\\nYou will need a local IPFS Node running to use the HTTP API (even when using Immerse). As an alternative, you can connect via the [Infura](https://infura.io/product/ipfs)\\'s dedicated IPFS gateway. Immerse provide both ways to interact with IPFS.\\r\\n\\r\\n## Installing\\r\\n\\r\\nto do: instructions on how to install library goes here\\r\\n\\r\\n## How to use\\r\\n\\r\\nTo adda file to IPFS, simply\\r\\n\\r\\n```python\\r\\nfrom immerse import httpapi\\r\\n\\r\\nurl = get_coreurl()\\r\\nresponse, json = add_items(url, \"path/to/file\")\\r\\n```\\r\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignoretest\n",
    "res, cont = gw.cat('QmUfwG4P6EA5xbD3De5bS7XKcBion8ReQj7m9ZjxaPvq3B'); cont"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d756ed",
   "metadata": {},
   "source": [
    "Like previously mentioned, infura supports read and write but not the complete set of functions that comes with the local node. Let's see an example. Here, the `ls` call lists the content of a directory. Let's try the same thing with `infura`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5b631028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Objects': [{'Hash': 'QmebrNeK8XYZ6P3oFgftSR6FzBqLmy3rdMzLvT1476bSWA',\n",
       "    'Links': [{'Name': '.ipynb_checkpoints',\n",
       "      'Hash': 'QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn',\n",
       "      'Size': 0,\n",
       "      'Type': 1,\n",
       "      'Target': ''},\n",
       "     {'Name': 'adult_data.csv',\n",
       "      'Hash': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V',\n",
       "      'Size': 3974475,\n",
       "      'Type': 2,\n",
       "      'Target': ''},\n",
       "     {'Name': 'fol1',\n",
       "      'Hash': 'QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn',\n",
       "      'Size': 0,\n",
       "      'Type': 1,\n",
       "      'Target': ''},\n",
       "     {'Name': 'test.txt',\n",
       "      'Hash': 'QmTT8vwdbnP9Ls8bSY1LMyW4a8bEwTYZa5izEoJMBtTPfb',\n",
       "      'Size': 24,\n",
       "      'Type': 2,\n",
       "      'Target': ''},\n",
       "     {'Name': 'test2.txt',\n",
       "      'Hash': 'QmWa7aPQWCkLAmV2pt1Wjj3uE7V3CG3KYMKBKsVAvWG649',\n",
       "      'Size': 23,\n",
       "      'Type': 2,\n",
       "      'Target': ''},\n",
       "     {'Name': 'test3.txt',\n",
       "      'Hash': 'Qmb6W6nVPYd5CJKFpC1zGGuoD7TYQLE5PGG1RHkHm2W3m9',\n",
       "      'Size': 32,\n",
       "      'Type': 2,\n",
       "      'Target': ''},\n",
       "     {'Name': 'test4.txt',\n",
       "      'Hash': 'QmWBXWXdo3fU6S35XBwHEVy9Trn2jYKtHWNALGZGTkmgr1',\n",
       "      'Size': 20,\n",
       "      'Type': 2,\n",
       "      'Target': ''}]}]}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignoretest\n",
    "r, res = gw.apipost(call='ls', filepath='QmebrNeK8XYZ6P3oFgftSR6FzBqLmy3rdMzLvT1476bSWA'); res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4b0cca44",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "Response Status Code: 403; Error Message: ipfs method not supported\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [96]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#ignoretest\u001b[39;00m\n\u001b[0;32m      2\u001b[0m gw \u001b[38;5;241m=\u001b[39m IPFSGateway(local\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m r, res \u001b[38;5;241m=\u001b[39m \u001b[43mgw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapipost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mls\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQmebrNeK8XYZ6P3oFgftSR6FzBqLmy3rdMzLvT1476bSWA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m; res\n",
      "Input \u001b[1;32mIn [84]\u001b[0m, in \u001b[0;36mIPFSGateway.apipost\u001b[1;34m(self, call, filepath, directory, chunk_size, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res, parse_response(res)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError (parse_error_message(res))\n",
      "\u001b[1;31mHTTPError\u001b[0m: Response Status Code: 403; Error Message: ipfs method not supported\n"
     ]
    }
   ],
   "source": [
    "#ignoretest\n",
    "gw = IPFSGateway(local=False)\n",
    "r, res = gw.apipost(call='ls', filepath='QmebrNeK8XYZ6P3oFgftSR6FzBqLmy3rdMzLvT1476bSWA'); res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68643db1",
   "metadata": {},
   "source": [
    "As can be inferred from the error message, `ls` call is not supported by inura ar this point. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9865f3",
   "metadata": {},
   "source": [
    "## IPFSFileSystem (fsspec-like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6c5b9672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IPFSFileSystem(AbstractFileSystem):\n",
    "    protocol = \"ipfs\"\n",
    "    def __init__(self, \n",
    "        local=True, # Use local IPFS deamon or not\n",
    "        coreurl:str=None, # Core URL of an alterative gateways to use \n",
    "        **kwargs):\n",
    "        'fsspec like read/write IPFS filesystem'\n",
    "        \n",
    "        super(IPFSFileSystem, self).__init__(local, **kwargs)\n",
    "        \n",
    "        if coreurl is None:\n",
    "            self.gw = IPFSGateway(local=local)\n",
    "        \n",
    "        else:\n",
    "            self.gw = IPFSGateway(coreurl)\n",
    "    \n",
    "    def ls(self, \n",
    "        cid:str, # Path of the IPFS object\n",
    "        detail=True, # Verbose\n",
    "        **kwargs):\n",
    "        'List the links of a IPFS file/directory'\n",
    "        \n",
    "        _, res = self.gw.apipost(\"ls\", arg=cid)\n",
    "        \n",
    "        links = res[0][\"Objects\"][0][\"Links\"]\n",
    "        types = {1: \"directory\", 2: \"file\"}\n",
    "        \n",
    "        if detail:\n",
    "            return [{\"name\": cid + \"/\" + link[\"Name\"],\n",
    "                     \"size\": link[\"Size\"],\n",
    "                     \"type\": types[link[\"Type\"]]}\n",
    "                    for link in links]\n",
    "        \n",
    "        else:\n",
    "            return [cid + \"/\" + link[\"Name\"]\n",
    "                    for link in links]\n",
    "        \n",
    "    def cat_file(self, \n",
    "        cid:str, # Path of the IPFS object\n",
    "    ):        \n",
    "        \n",
    "        r, data = self.gw.cat(cid)      \n",
    "        \n",
    "        return r.content\n",
    "                \n",
    "    def _open(\n",
    "        self,\n",
    "        cid, # Path of the IPFS object\n",
    "        mode=\"rb\",\n",
    "        block_size=None,\n",
    "        autocommit=True,\n",
    "        cache_options=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        'Return raw bytes-mode file-like from the file-system'\n",
    "        \n",
    "        return IPFSBufferedFile(\n",
    "            self,\n",
    "            cid,\n",
    "            mode,\n",
    "            block_size,\n",
    "            autocommit,\n",
    "            cache_options=cache_options,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    def info(self, \n",
    "        cid, # Path of the IPFS object\n",
    "        **kwargs):\n",
    "        \n",
    "        path = self._strip_protocol(cid)\n",
    "\n",
    "        headers = {\"Accept-Encoding\": \"identity\"}  # this ensures correct file size\n",
    "        response_headers = self.gw.head(cid, headers)\n",
    "\n",
    "        info = {\"name\": cid}\n",
    "        if \"X-Content-Length\" in response_headers:\n",
    "            info[\"size\"] = int(response_headers[\"X-Content-Length\"])\n",
    "        elif \"X-Content-Range\" in response_headers:\n",
    "            info[\"size\"] = int(response_headers[\"X-Content-Range\"].split(\"/\")[1])\n",
    "\n",
    "        if \"ETag\" in response_headers:\n",
    "            etag = response_headers[\"ETag\"].strip(\"\\\"\")\n",
    "            info[\"ETag\"] = etag\n",
    "            if etag.startswith(\"DirIndex\"):\n",
    "                info[\"type\"] = \"directory\"\n",
    "                info[\"CID\"] = etag.split(\"-\")[-1]\n",
    "            else:\n",
    "                info[\"type\"] = \"file\"\n",
    "                info[\"CID\"] = etag\n",
    "        return info\n",
    "    \n",
    "    def write(self,\n",
    "        filepath, # Path to file/files/directories to write to IPFS\n",
    "        directory=False, # Is filepath a directory\n",
    "        chunk_size=200000, # Chunk size to use\n",
    "        **kwargs\n",
    "    ):\n",
    "        'Write the given file/files/directories to the IPFS network'\n",
    "        \n",
    "        return self.gw.apipost('add', filepath=filepath, directory=directory, chunk_size=chunk_size, **kwargs)\n",
    "    \n",
    "    def read_csv(self, \n",
    "        cid:str,\n",
    "        delimeter:str=','\n",
    "    ):\n",
    "        r, data = self.gw.cat(cid)      \n",
    "        \n",
    "        return pd.read_csv(StringIO(data), delimiter=delimeter)\n",
    "    \n",
    "    def read_json(self, \n",
    "        cid:str, \n",
    "    ):\n",
    "        r, data = self.gw.cat(cid)      \n",
    "        \n",
    "        return pd.read_json(StringIO(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cbecdc",
   "metadata": {},
   "source": [
    "### Using IPFSSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "30176b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignoretest\n",
    "fs = IPFSFileSystem(local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2aeb38",
   "metadata": {},
   "source": [
    "call the `ls` method to list the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c0e79f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 262144,\n",
       "  'type': 'file'},\n",
       " {'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 262144,\n",
       "  'type': 'file'},\n",
       " {'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 262144,\n",
       "  'type': 'file'},\n",
       " {'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 262144,\n",
       "  'type': 'file'},\n",
       " {'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 262144,\n",
       "  'type': 'file'},\n",
       " {'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 262144,\n",
       "  'type': 'file'},\n",
       " {'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 262144,\n",
       "  'type': 'file'},\n",
       " {'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 262144,\n",
       "  'type': 'file'},\n",
       " {'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 262144,\n",
       "  'type': 'file'},\n",
       " {'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 262144,\n",
       "  'type': 'file'},\n",
       " {'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 262144,\n",
       "  'type': 'file'},\n",
       " {'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 262144,\n",
       "  'type': 'file'},\n",
       " {'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 262144,\n",
       "  'type': 'file'},\n",
       " {'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 262144,\n",
       "  'type': 'file'},\n",
       " {'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 262144,\n",
       "  'type': 'file'},\n",
       " {'name': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V/',\n",
       "  'size': 42315,\n",
       "  'type': 'file'}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignoretest\n",
    "res = fs.ls('QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V'); res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5958693",
   "metadata": {},
   "source": [
    "Use the `open` and `read` on a IPFS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "044598cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'# Welcome to Immerse by Algovera\\r\\n> A python library by Algovera to interact with IPFS and IPFS ecosystem such as the common pinning services\\r\\n\\r\\n\\r\\n## What is Immerse?\\r\\n\\r\\nImmerse is a python library by Algovera to interact with IPFS and IPFS ecosystem such as the common pinning services. It is designed by data scientists for data scientists to interact with the IPFS ecosystem without leaving the comfort of python and jupyter notebook.\\r\\n\\r\\nYou can learn more about IPFS [here](https://ipfs.io/#why)\\r\\n\\r\\nIPFS is built using the go-lang and javascript. With Immerse, you can interact with IPFS using the exposed [HTTP RPC API](https://docs.ipfs.io/reference/http/api/#getting-started). \\r\\n\\r\\nYou will need a local IPFS Node running to use the HTTP API (even when using Immerse). As an alternative, you can connect via the [Infura](https://infura.io/product/ipfs)\\'s dedicated IPFS gateway. Immerse provide both ways to interact with IPFS.\\r\\n\\r\\n## Installing\\r\\n\\r\\nto do: instructions on how to install library goes here\\r\\n\\r\\n## How to use\\r\\n\\r\\nTo adda file to IPFS, simply\\r\\n\\r\\n```python\\r\\nfrom immerse import httpapi\\r\\n\\r\\nurl = get_coreurl()\\r\\nresponse, json = add_items(url, \"path/to/file\")\\r\\n```\\r\\n'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignoretest\n",
    "fs.open('QmUfwG4P6EA5xbD3De5bS7XKcBion8ReQj7m9ZjxaPvq3B').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c76a84",
   "metadata": {},
   "source": [
    "`Write` a file, files or a directory to IPFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7ac04103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Response [200]>,\n",
       " [{'Name': 'output/adult_data.csv',\n",
       "   'Hash': 'QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V',\n",
       "   'Size': '3975476'},\n",
       "  {'Name': 'output/test.txt',\n",
       "   'Hash': 'QmTT8vwdbnP9Ls8bSY1LMyW4a8bEwTYZa5izEoJMBtTPfb',\n",
       "   'Size': '32'},\n",
       "  {'Name': 'output/test2.txt',\n",
       "   'Hash': 'QmWa7aPQWCkLAmV2pt1Wjj3uE7V3CG3KYMKBKsVAvWG649',\n",
       "   'Size': '31'},\n",
       "  {'Name': 'output/test3.txt',\n",
       "   'Hash': 'Qmb6W6nVPYd5CJKFpC1zGGuoD7TYQLE5PGG1RHkHm2W3m9',\n",
       "   'Size': '40'},\n",
       "  {'Name': 'output/fol1',\n",
       "   'Hash': 'QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn',\n",
       "   'Size': '4'},\n",
       "  {'Name': 'output',\n",
       "   'Hash': 'QmeyTiqrD6oo4eQXbAt7hZn3ASzpcP3Kvb1rc9qznEowEw',\n",
       "   'Size': '3975844'}])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignoretest\n",
    "fs.write('output', directory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a793b0ed",
   "metadata": {},
   "source": [
    "Read a csv straight from IPFS into a `pandas` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "67ebef54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   fnlwgt   education   education-num  \\\n",
       "0   39          State-gov    77516   Bachelors              13   \n",
       "1   50   Self-emp-not-inc    83311   Bachelors              13   \n",
       "2   38            Private   215646     HS-grad               9   \n",
       "3   53            Private   234721        11th               7   \n",
       "4   28            Private   338409   Bachelors              13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "    capital-gain   capital-loss   hours-per-week  native-country  salary  \n",
       "0           2174              0               40   United-States   <=50K  \n",
       "1              0              0               13   United-States   <=50K  \n",
       "2              0              0               40   United-States   <=50K  \n",
       "3              0              0               40   United-States   <=50K  \n",
       "4              0              0               40            Cuba   <=50K  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignoretest\n",
    "df = fs.read_csv('QmZnxARhJWsCbTxiAzoRhnxHgMtoEkNJNS8DGLCBEMvm4V'); df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96202af5",
   "metadata": {},
   "source": [
    "Similarly, read a json straight from IPFS into a `pandas` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "32b11541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepalLength</th>\n",
       "      <th>sepalWidth</th>\n",
       "      <th>petalLength</th>\n",
       "      <th>petalWidth</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepalLength  sepalWidth  petalLength  petalWidth species\n",
       "0          5.1         3.5          1.4         0.2  setosa\n",
       "1          4.9         3.0          1.4         0.2  setosa\n",
       "2          4.7         3.2          1.3         0.2  setosa\n",
       "3          4.6         3.1          1.5         0.2  setosa\n",
       "4          5.0         3.6          1.4         0.2  setosa"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignoretest\n",
    "df = fs.read_json('QmaQ3MEK664wo8DQUu8okvGF3EaQivE8e2a7cfS3Lpqr8e'); df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb296caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a314c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
